{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Problem_C3.ipynb","provenance":[],"authorship_tag":"ABX9TyNOj8vlbDPsf0REcbl7EXOQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yXdufvICnJXa","executionInfo":{"status":"ok","timestamp":1656070988579,"user_tz":-420,"elapsed":2928050,"user":{"displayName":"KEVIN ADRIAN HALIM","userId":"18434347424817665992"}},"outputId":"03319b97-e168-47b7-a75f-4fc4b0378d11"},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 2000 images belonging to 2 classes.\n","Found 1000 images belonging to 2 classes.\n","Epoch 1/40\n","100/100 [==============================] - 61s 601ms/step - loss: 0.6945 - accuracy: 0.5200 - val_loss: 0.6780 - val_accuracy: 0.6180\n","Epoch 2/40\n","100/100 [==============================] - 60s 597ms/step - loss: 0.6763 - accuracy: 0.5470 - val_loss: 0.6510 - val_accuracy: 0.6190\n","Epoch 3/40\n","100/100 [==============================] - 61s 610ms/step - loss: 0.6629 - accuracy: 0.5890 - val_loss: 0.6335 - val_accuracy: 0.6300\n","Epoch 4/40\n","100/100 [==============================] - 60s 599ms/step - loss: 0.6490 - accuracy: 0.6105 - val_loss: 0.6180 - val_accuracy: 0.6600\n","Epoch 5/40\n","100/100 [==============================] - 60s 600ms/step - loss: 0.6396 - accuracy: 0.6150 - val_loss: 0.6068 - val_accuracy: 0.6540\n","Epoch 6/40\n","100/100 [==============================] - 60s 598ms/step - loss: 0.6303 - accuracy: 0.6480 - val_loss: 0.6068 - val_accuracy: 0.6530\n","Epoch 7/40\n","100/100 [==============================] - 60s 599ms/step - loss: 0.6238 - accuracy: 0.6505 - val_loss: 0.5870 - val_accuracy: 0.6790\n","Epoch 8/40\n","100/100 [==============================] - 60s 597ms/step - loss: 0.6121 - accuracy: 0.6575 - val_loss: 0.5792 - val_accuracy: 0.6870\n","Epoch 9/40\n","100/100 [==============================] - 60s 600ms/step - loss: 0.6055 - accuracy: 0.6705 - val_loss: 0.5740 - val_accuracy: 0.6840\n","Epoch 10/40\n","100/100 [==============================] - 61s 612ms/step - loss: 0.6010 - accuracy: 0.6715 - val_loss: 0.6057 - val_accuracy: 0.6510\n","Epoch 11/40\n","100/100 [==============================] - 60s 603ms/step - loss: 0.5935 - accuracy: 0.6765 - val_loss: 0.5709 - val_accuracy: 0.6960\n","Epoch 12/40\n","100/100 [==============================] - 60s 599ms/step - loss: 0.5904 - accuracy: 0.6765 - val_loss: 0.5574 - val_accuracy: 0.7030\n","Epoch 13/40\n","100/100 [==============================] - 60s 598ms/step - loss: 0.5952 - accuracy: 0.6815 - val_loss: 0.6079 - val_accuracy: 0.6490\n","Epoch 14/40\n","100/100 [==============================] - 62s 615ms/step - loss: 0.5774 - accuracy: 0.6910 - val_loss: 0.5565 - val_accuracy: 0.7050\n","Epoch 15/40\n","100/100 [==============================] - 60s 601ms/step - loss: 0.5854 - accuracy: 0.6860 - val_loss: 0.5761 - val_accuracy: 0.6820\n","Epoch 16/40\n","100/100 [==============================] - 60s 601ms/step - loss: 0.5784 - accuracy: 0.6975 - val_loss: 0.5667 - val_accuracy: 0.6910\n","Epoch 17/40\n","100/100 [==============================] - 60s 600ms/step - loss: 0.5778 - accuracy: 0.6930 - val_loss: 0.5409 - val_accuracy: 0.7110\n","Epoch 18/40\n","100/100 [==============================] - 60s 599ms/step - loss: 0.5771 - accuracy: 0.7010 - val_loss: 0.5520 - val_accuracy: 0.7090\n","Epoch 19/40\n","100/100 [==============================] - 60s 601ms/step - loss: 0.5662 - accuracy: 0.7030 - val_loss: 0.5423 - val_accuracy: 0.7080\n","Epoch 20/40\n","100/100 [==============================] - 61s 610ms/step - loss: 0.5651 - accuracy: 0.7040 - val_loss: 0.5250 - val_accuracy: 0.7280\n","Epoch 21/40\n","100/100 [==============================] - 60s 598ms/step - loss: 0.5616 - accuracy: 0.7030 - val_loss: 0.5478 - val_accuracy: 0.7120\n","Epoch 22/40\n","100/100 [==============================] - 60s 598ms/step - loss: 0.5590 - accuracy: 0.7055 - val_loss: 0.5334 - val_accuracy: 0.7240\n","Epoch 23/40\n","100/100 [==============================] - 61s 614ms/step - loss: 0.5614 - accuracy: 0.7230 - val_loss: 0.5463 - val_accuracy: 0.7030\n","Epoch 24/40\n","100/100 [==============================] - 60s 601ms/step - loss: 0.5474 - accuracy: 0.7175 - val_loss: 0.5374 - val_accuracy: 0.7240\n","Epoch 25/40\n","100/100 [==============================] - 60s 599ms/step - loss: 0.5570 - accuracy: 0.7115 - val_loss: 0.5146 - val_accuracy: 0.7300\n","Epoch 26/40\n","100/100 [==============================] - 60s 598ms/step - loss: 0.5524 - accuracy: 0.7220 - val_loss: 0.5240 - val_accuracy: 0.7320\n","Epoch 27/40\n","100/100 [==============================] - 61s 610ms/step - loss: 0.5515 - accuracy: 0.7165 - val_loss: 0.5415 - val_accuracy: 0.7250\n","Epoch 28/40\n","100/100 [==============================] - 60s 600ms/step - loss: 0.5421 - accuracy: 0.7240 - val_loss: 0.5274 - val_accuracy: 0.7230\n","Epoch 29/40\n","100/100 [==============================] - 60s 600ms/step - loss: 0.5423 - accuracy: 0.7230 - val_loss: 0.5035 - val_accuracy: 0.7460\n","Epoch 30/40\n","100/100 [==============================] - 61s 611ms/step - loss: 0.5342 - accuracy: 0.7270 - val_loss: 0.5041 - val_accuracy: 0.7460\n","Epoch 31/40\n","100/100 [==============================] - 60s 602ms/step - loss: 0.5452 - accuracy: 0.7275 - val_loss: 0.5107 - val_accuracy: 0.7270\n","Epoch 32/40\n","100/100 [==============================] - 60s 604ms/step - loss: 0.5393 - accuracy: 0.7195 - val_loss: 0.5370 - val_accuracy: 0.7370\n","Epoch 33/40\n","100/100 [==============================] - 61s 612ms/step - loss: 0.5289 - accuracy: 0.7420 - val_loss: 0.4902 - val_accuracy: 0.7520\n","Epoch 34/40\n","100/100 [==============================] - 60s 601ms/step - loss: 0.5219 - accuracy: 0.7410 - val_loss: 0.5004 - val_accuracy: 0.7660\n","Epoch 35/40\n","100/100 [==============================] - 60s 598ms/step - loss: 0.5202 - accuracy: 0.7345 - val_loss: 0.4965 - val_accuracy: 0.7480\n","Epoch 36/40\n","100/100 [==============================] - 60s 598ms/step - loss: 0.5331 - accuracy: 0.7350 - val_loss: 0.5082 - val_accuracy: 0.7610\n","Epoch 37/40\n","100/100 [==============================] - 60s 600ms/step - loss: 0.5227 - accuracy: 0.7495 - val_loss: 0.5005 - val_accuracy: 0.7580\n","Epoch 38/40\n","100/100 [==============================] - 60s 599ms/step - loss: 0.5235 - accuracy: 0.7285 - val_loss: 0.5084 - val_accuracy: 0.7490\n","Epoch 39/40\n","100/100 [==============================] - 60s 599ms/step - loss: 0.5141 - accuracy: 0.7470 - val_loss: 0.5201 - val_accuracy: 0.7170\n","Epoch 40/40\n","100/100 [==============================] - 61s 613ms/step - loss: 0.5200 - accuracy: 0.7450 - val_loss: 0.4795 - val_accuracy: 0.7720\n"]}],"source":["# =======================================================================================================\n","# PROBLEM C3\n","#\n","# Build a CNN based classifier for Cats vs Dogs dataset.\n","# Your input layer should accept 150x150 with 3 bytes color as the input shape.\n","# This is unlabeled data, use ImageDataGenerator to automatically label it.\n","# Don't use lambda layers in your model.\n","#\n","# The dataset used in this problem is originally published in https://www.kaggle.com/c/dogs-vs-cats/data\n","#\n","# Desired accuracy and validation_accuracy > 72%\n","# ========================================================================================================\n","\n","import tensorflow as tf\n","import urllib.request\n","import zipfile\n","import tensorflow as tf\n","import os\n","from tensorflow.keras.optimizers import RMSprop\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","\n","def solution_C3():\n","    data_url = 'https://github.com/dicodingacademy/assets/raw/main/Simulation/machine_learning/cats_and_dogs.zip'\n","    urllib.request.urlretrieve(data_url, 'cats_and_dogs.zip')\n","    local_file = 'cats_and_dogs.zip'\n","    zip_ref = zipfile.ZipFile(local_file, 'r')\n","    zip_ref.extractall('data/')\n","    zip_ref.close()\n","\n","    BASE_DIR = 'data/cats_and_dogs'\n","    train_dir = os.path.join(BASE_DIR, 'train')\n","    validation_dir = os.path.join(BASE_DIR, 'validation')\n","\n","    train_datagen =  ImageDataGenerator(rescale = 1/255,\n","                                              rotation_range=40,\n","                                              width_shift_range=0.2,\n","                                              height_shift_range=0.2,\n","                                              shear_range=0.2,\n","                                              zoom_range=0.2,\n","                                              horizontal_flip=True,\n","                                              fill_mode='nearest')\n","    validation_datagen = ImageDataGenerator(rescale = 1/255)\n","\n","    # YOUR IMAGE SIZE SHOULD BE 150x150\n","    # Make sure you used \"categorical\"\n","    train_generator =  train_datagen.flow_from_directory(\"/content/data/cats_and_dogs_filtered/train\",\n","        target_size = (150,150),\n","        batch_size = 20 , \n","        class_mode = \"binary\"\n","    )\n","\n","    validation_generator = validation_datagen. flow_from_directory(\n","        \"/content/data/cats_and_dogs_filtered/validation\",\n","        target_size = (150,150),\n","        batch_size = 20 , \n","        class_mode = \"binary\"\n","    )\n","\n","    model = tf.keras.models.Sequential([\n","                                        tf.keras.layers.Conv2D(16,(3,3),\n","                                                               activation = \"relu\",\n","                                                               input_shape = (150,150,3)\n","                                                               ),\n","                                        tf.keras.layers.MaxPooling2D(2,2),\n","                                        tf.keras.layers.Conv2D(32,(3,3),activation = \"relu\"),\n","                                        tf.keras.layers.MaxPooling2D(2,2),\n","                                        tf.keras.layers.Conv2D(64,(3,3), activation = \"relu\"),\n","                                        tf.keras.layers.MaxPooling2D(2,2),\n","                                        tf.keras.layers.Flatten(),\n","                                        tf.keras.layers.Dense(128, activation = \"relu\"),\n","                                        tf.keras.layers.Dense(1,activation = \"sigmoid\")\n","    ])\n","    model.compile(loss = \"binary_crossentropy\",\n","                  optimizer = RMSprop(learning_rate = 0.0001),\n","                  metrics = [\"accuracy\"])\n","    \n","    model.fit(  train_generator, epochs = 40,          steps_per_epoch = 100, \n","          validation_data = validation_generator,\n","          validation_steps = 50)\n","\n","    return model\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model = solution_C3()\n","    model.save(\"model_C3.h5\")\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"GN9udDp2JlET"},"execution_count":null,"outputs":[]}]}