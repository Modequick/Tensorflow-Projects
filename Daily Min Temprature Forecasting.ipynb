{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Problem_c5.ipynb","provenance":[],"authorship_tag":"ABX9TyMHgtK2DS24ddftYiNXyrte"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Na0ncDbN81U5","executionInfo":{"status":"ok","timestamp":1656079143983,"user_tz":-420,"elapsed":134120,"user":{"displayName":"KEVIN ADRIAN HALIM","userId":"18434347424817665992"}},"outputId":"b9791818-7abf-417a-865c-c55313fb093c"},"outputs":[{"output_type":"stream","name":"stdout","text":["<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))>\n","(2500,)\n","<PrefetchDataset element_spec=(TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None), TensorSpec(shape=(None, None, 1), dtype=tf.float64, name=None))>\n","(2500,)\n","Epoch 1/20\n","10/10 [==============================] - 10s 587ms/step - loss: 0.0272 - mae: 0.1751 - val_loss: 0.0094 - val_mae: 0.1022\n","Epoch 2/20\n","10/10 [==============================] - 5s 477ms/step - loss: 0.0102 - mae: 0.1106 - val_loss: 0.0102 - val_mae: 0.1099\n","Epoch 3/20\n","10/10 [==============================] - 5s 482ms/step - loss: 0.0093 - mae: 0.1053 - val_loss: 0.0094 - val_mae: 0.1064\n","Epoch 4/20\n","10/10 [==============================] - 5s 478ms/step - loss: 0.0089 - mae: 0.1043 - val_loss: 0.0090 - val_mae: 0.1042\n","Epoch 5/20\n","10/10 [==============================] - 5s 479ms/step - loss: 0.0084 - mae: 0.1015 - val_loss: 0.0089 - val_mae: 0.1049\n","Epoch 6/20\n","10/10 [==============================] - 5s 485ms/step - loss: 0.0081 - mae: 0.0996 - val_loss: 0.0074 - val_mae: 0.0949\n","Epoch 7/20\n","10/10 [==============================] - 5s 482ms/step - loss: 0.0079 - mae: 0.0984 - val_loss: 0.0081 - val_mae: 0.0999\n","Epoch 8/20\n","10/10 [==============================] - 5s 480ms/step - loss: 0.0078 - mae: 0.0980 - val_loss: 0.0073 - val_mae: 0.0944\n","Epoch 9/20\n","10/10 [==============================] - 5s 479ms/step - loss: 0.0072 - mae: 0.0942 - val_loss: 0.0067 - val_mae: 0.0907\n","Epoch 10/20\n","10/10 [==============================] - 5s 481ms/step - loss: 0.0083 - mae: 0.1022 - val_loss: 0.0058 - val_mae: 0.0831\n","Epoch 11/20\n","10/10 [==============================] - 5s 481ms/step - loss: 0.0065 - mae: 0.0897 - val_loss: 0.0103 - val_mae: 0.1170\n","Epoch 12/20\n","10/10 [==============================] - 5s 486ms/step - loss: 0.0068 - mae: 0.0911 - val_loss: 0.0062 - val_mae: 0.0872\n","Epoch 13/20\n","10/10 [==============================] - 5s 487ms/step - loss: 0.0070 - mae: 0.0932 - val_loss: 0.0055 - val_mae: 0.0821\n","Epoch 14/20\n","10/10 [==============================] - 5s 488ms/step - loss: 0.0071 - mae: 0.0940 - val_loss: 0.0065 - val_mae: 0.0891\n","Epoch 15/20\n","10/10 [==============================] - 5s 483ms/step - loss: 0.0065 - mae: 0.0895 - val_loss: 0.0065 - val_mae: 0.0895\n","Epoch 16/20\n","10/10 [==============================] - 5s 480ms/step - loss: 0.0071 - mae: 0.0941 - val_loss: 0.0055 - val_mae: 0.0817\n","Epoch 17/20\n","10/10 [==============================] - 5s 477ms/step - loss: 0.0062 - mae: 0.0877 - val_loss: 0.0060 - val_mae: 0.0860\n","Epoch 18/20\n","10/10 [==============================] - 5s 482ms/step - loss: 0.0068 - mae: 0.0919 - val_loss: 0.0053 - val_mae: 0.0803\n","Epoch 19/20\n","10/10 [==============================] - 5s 476ms/step - loss: 0.0062 - mae: 0.0880 - val_loss: 0.0058 - val_mae: 0.0843\n","Epoch 20/20\n","10/10 [==============================] - 5s 476ms/step - loss: 0.0062 - mae: 0.0876 - val_loss: 0.0054 - val_mae: 0.0816\n"]}],"source":["# ============================================================================================\n","# PROBLEM C5\n","#\n","# Build and train a neural network model using the Daily Min Temperature.csv dataset.\n","# Use MAE as the metrics of your neural network model.\n","# We provided code for normalizing the data. Please do not change the code.\n","# Do not use lambda layers in your model.\n","#\n","# The dataset used in this problem is downloaded from https://github.com/jbrownlee/Datasets\n","#\n","# Desired MAE < 0.19 on the normalized dataset.\n","# ============================================================================================\n","\n","import tensorflow as tf\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import csv\n","import urllib\n","import pandas as pd\n","from tensorflow.keras.optimizers import RMSprop\n","\n","def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n","    series = tf.expand_dims(series, axis=-1)\n","    ds = tf.data.Dataset.from_tensor_slices(series)\n","    ds = ds.window(window_size + 1, shift=1, drop_remainder=True)\n","    ds = ds.flat_map(lambda w: w.batch(window_size + 1))\n","    ds = ds.shuffle(shuffle_buffer)\n","    ds = ds.map(lambda w: (w[:-1], w[1:]))\n","    return ds.batch(batch_size).prefetch(1)\n","\n","\n","def solution_C5():\n","    df = pd.read_csv('https://raw.githubusercontent.com/jbrownlee/Datasets/master/daily-min-temperatures.csv')\n","    series = df[\"Temp\"]\n","\n","    # Normalization Function. DO NOT CHANGE THIS CODE\n","    min=np.min(series)\n","    max=np.max(series)\n","    series -= min\n","    series /= max\n","\n","    # DO NOT CHANGE THIS CODE\n","    split_time=2500\n","\n","\n","    x_train=  series[:split_time]\n","    x_valid=  series[split_time:]\n","    # DO NOT CHANGE THIS CODE\n","    window_size=64\n","    batch_size=256\n","    shuffle_buffer_size=1000\n","\n","    train_set=windowed_dataset(\n","        x_train, window_size, batch_size, shuffle_buffer_size)\n","    print(train_set)\n","    print(x_train.shape)\n","\n","    valid_set=windowed_dataset(\n","        x_valid, window_size, batch_size, shuffle_buffer_size)\n","    print(train_set)\n","    print(x_train.shape)\n","\n","    model=tf.keras.models.Sequential([\n","        tf.keras.layers.Conv1D(16,3,\n","                               strides = 1 ,\n","                               padding = \"causal\",\n","                               activation = \"relu\",\n","                               input_shape = [None,1]    ),\n","\n","        tf.keras.layers.LSTM(64,return_sequences = True),\n","        tf.keras.layers.LSTM(64,return_sequences = True),\n","        tf.keras.layers.Dense(512, activation = 'relu'),\n","        tf.keras.layers.Dense(1),\n","    ])\n","\n","    model.compile(loss = tf.keras.losses.Huber() ,\n","                  optimizer = RMSprop(learning_rate = 0.001), \n","                  metrics = [\"mae\"])\n","    \n","    model.fit(train_set,\n","              epochs = 20, \n","              validation_data =valid_set)\n","    # YOUR CODE HERE\n","    return model\n","\n","\n","\n","# The code below is to save your model as a .h5 file.\n","# It will be saved automatically in your Submission folder.\n","if __name__ == '__main__':\n","    # DO NOT CHANGE THIS CODE\n","    model=solution_C5()\n","    model.save(\"model_C5.h5\")\n"]},{"cell_type":"code","source":[""],"metadata":{"id":"4mEWFKqJ9O2S"},"execution_count":null,"outputs":[]}]}